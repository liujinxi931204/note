## 什么是事务  

维基百科对事务的描述如下 ：  

数据库事务通常包含了一个序列的对数据库的读/写操作。包含有以下两个目的：

1. 为数据库操作序列提供了一个从失败中恢复到正常状态的方法，同时提供了数据库即使在异常状态下仍能保持一致性的方法。
2. 当多个应用程序在并发访问数据库时，可以在这些应用程序之间提供一个隔离方法，以防止彼此的操作互相干扰。

当事务被提交给了数据库管理系统（DBMS），则DBMS需要确保该事务中的所有操作都成功完成且其结果被永久保存在数据库中，如果事务中有的操作没有成功完成，则事务中的所有操作都需要回滚，回到事务执行前的状态；同时，该事务对数据库或者其他事务的执行无影响，所有的事务都好像在独立的运行。

众所周知，事务具有ACID四大特性。维基百科对ACID的描述如下：  

并非任意的对数据库的操作序列都是数据库事务。数据库事务拥有以下四个特性，习惯上被称之为**ACID特性**。

- **原子性（Atomicity）**：事务作为一个整体被执行，包含在其中的对数据库的操作要么全部被执行，要么都不执行。
- **一致性（Consistency）**：事务应确保数据库的状态从一个一致状态转变为另一个一致状态。一致状态的含义是数据库中的数据应满足完整性约束。
- **隔离性（Isolation）**：多个事务并发执行时，一个事务的执行不应影响其他事务的执行。
- **持久性（Durability）**：已被提交的事务对数据库的修改应该永久保存在数据库中。

## 单机事务   

传统单机情况下，数据库是怎么实现ACID的呢？以MySQL为例，原子性通过undo日志实现，持久性通过redo日志实现，隔离性通过锁和MVCC(Multi Version Concurrency Control)和undo日志实现，原子性、持久性和隔离性共同保证一致性  

### redo日志  

首先需要简单说一下MySQL的数据管理方式。MySQL中的数据并不是每次都从磁盘中读取的，而是在内存中有一个Buffer Pool，用于存放磁盘中的热点数据页。读取数据时先从Buffer Pool中读取，如果没有的话，再从磁盘中读取，然后再保存在Buffer Pool中。写入数据时，也是先写入到Buffer Pool中，然后再把Buffer Pool中的数据定期写入磁盘。  

 虽然Buffer Pool提高了MySQL效率，但是会导致一个问题。如果写入磁盘之前，MySQL宕机了，Buffer Pool中的数据还没写入到磁盘的数据就会丢失，所以MySQL设计了redo日志来解决这个问题。  

redo日志由内存中的redo log buffer和redo日志文件组成。修改数据时，先写redo日志添加到内存中的redo log buffer中，然后修改Buffer Pool中的数据。提交这次事务时，可以选择是否将redo log buffer中的日志刷新到磁盘。用户可以通过innodb_flush_log_at_trx_commit参数来控制写入磁盘的时机，有三种取值：  

+ 0，事务提交时不写入磁盘，由线程每秒写入磁盘一次  

+ 1，事务提交时调用fsync()强制写盘  

+ 2，事务提交时写入文件系统缓存，由操作系统决定何时将缓存写入磁盘  

![img](https://gitee.com/liujinxi931204/typoraImage/raw/master/img/mysql%20update.png)  

如果设置为0，MySQL服务进程宕机时有可能丢失数据；如果设置为2，操作系统宕机时有可能丢失数据  

redo日志并不一定是事务提交才会写盘，如果innodb_flush_log_at_trx_commit设置为0，即使还没有提交，也可能写入磁盘  

如果每次修改数据都需要写redo日志到磁盘，那为什么不把Buffer Pool中的数据直接写入磁盘呢？原因有两个：  

+ 直接刷新数据是一个随机IO，每次修改的数据在不同的数据页中，而redo日志是连续的，写盘是顺序IO  

+ 直接刷盘是以数据页为单位，MySQL默认是16KB，即使修改的数据只有一个字节也需要写16KB。而redo日志只包含修改的数据，数据量要小很多 

### undo日志  

undo日志用于事务的回滚和MVCC，分别对应原子性和隔离性。MySQL中修改数据时，并不是简单地在当前数据上修改，而是先把修改前的数据保存在undo日志中，然后修改当前数据并且在当前数据中增加一个指针指向修改前的数据。如下图所示，undo日志组成一个链表  

![undo log](https://gitee.com/liujinxi931204/typoraImage/raw/master/img/undo%20log.png)  

图中undo列表由三个SQL操作组成，左上角为当前记录的内容，第二个方块时最后一条SQL语句对应的undo日志，日志重保存了事务ID(TRX_ID)和修改前的字段内容("B")，最后一个方块是insert语句对应的undo日志  

undo日志还有一个undo header头部信息，其中一个字段是TRX_UNDO_STAE，表示undo日志的状态，取值有下面几个  

+ TRX_UNDO_ACTIVE：初始状态  

+ TRX_UNDO_CACHED  

+ TRX_UNDO_TO_FREE：可以释放  

+ TRX_UNDO_TO_PURGE：可以清理  

+ TRX_UNDO_PREPARED：准备状态，还未提交  

undo日志在事务还未提交前是TRX_UNDO_PERPARED状态，事务提交后，根据不同的操作类型转换成TRX_UNDO_CACHED、TRX_UNDO_TO_FREE或者TRX_UNDO_TO_PURGE状态，表示满足一定条件后可以释放；事务如果需要回滚，必须是TRX_UNDO_ACTIVE或者TRX_UNDO_PERPARED状态。此时从undo日志中取出上一次的数据作为当前数据的值。需要说明的是，写undo日志本身也会产生相应的redo日志  

### MVCC  

MVCC的全称是Multi Version Concurrency Control多版本并发控制。它的作用是解决不同事务之间并发执行的时候，数据修改的隔离性问题。数据库有四种隔离级别，由低到高分别是：  

+ 读未提交(READ UNCOMMITED)：允许读取其他事务未提交的修改  

+ 读已提交(READ COMMITED)：只能读取其他事务已提交的修改  

+ 可重复读(REPEATABLE READ)：同一个事务内，多次读取操作得到的每个数据行的内容是一样的  

+ 串行化(SERIALIZABLE)：事务执行不受其他事务的影响，就像各个事务之间是按顺序执行的  

串行化是指多个事务执行是按照某种顺序执行的，每个事务都是一个原子操作，一个事务的执行过程中不会看到另一个事务的中间状态，但不保证这个顺序一定是时间上的先后顺序。比如事务ABC先后请求，实际执行的顺序可能是ACB  

不同的隔离级别可以解决不同级别的读问题  

| 隔离级别 |   脏读   | 不可重复读 |   幻读   |
| :------: | :------: | :--------: | :------: |
| 读未提交 | 可能发生 |  可能发生  | 可能发生 |
| 读已提交 |    -     |  可能发生  | 可能发生 |
| 可重复读 |    -     |     -      | 可能发生 |
|  串行化  |    -     |     -      |    -     |

**脏读**  

当一个事务允许读取另外一个事务修改但是未提交的数据时，就可能发生脏读  

**不可重复读**  

在一次事务中，当一行数据获取两遍得到不同的结果表示发生了不可重复读  

**幻读**  

在事务执行过程中，当两个完成相同的查询语句执行得到不同的结果集，这种现象称为幻读  

 对于隔离性，一种方法是基于锁。这种方案的问题是性能可能比较低下，尤其是读操作也要加锁的时候。另一种方案是MVCC。MVCC用于替代读锁，写依旧需要加锁。MVCC和undo日志是如何支持不同的隔离级别，解决读问题呢？  

对于读未提交，只要记录读取记录当前版本的值就好了  

对于读已提交，在执行事务中的每个查询语句时，MySQL会生成一个叫做视图read view的数据结构，包含以下内容  

+ m_ids：所有正在执行的事务ID，这些事务还没有提交  

+ min_trx_id：生成read view时正在执行的最小事务ID  

+ max_trx_id：生成read view时系统应该分配的下一个事务ID  

+ creator_trx_id：生成read view时事务本身的ID  

访问数据时，根据以下规则判断某个版本的数据是否可见  

1. 如果当前版本数据的事务ID和creator_trx_id相同，说明是当前事务修改的记录，此时该版本数据可见  

2. 如果当前版本数据的事务ID小于min_trx_id，说明是已经提交的事务做的修改，该版本数据可见  

3. 如果当前版本数据的事务ID大于等于max_trx_id，说明是该版本的事务在read view创建之后生成的，该版本数据不可见  

4. 如果当前版本数据的事务ID在min_trx_id和max_trx_id之间，并且在m_ids内，该版本数据不可见；如果不在m_ids内，该版本数据可见  

如果当前版本数据不可见，使用前面介绍的undo日志，根据ROLL PTR回滚指针找到上一个版本的数据，判断上一个版本的数据是否可见，如果不可见，沿着undo日志链表找到符合条件的数据版本  

对于可重复读，和已提交读的差别在于已提交读是在事务中每条查询语句执行的时候都会生成read view，而可重复读是在事务一开始的时候生成read view  

MVCC解决了脏读、不可重复读和部分幻读问题。对于快照读，MVCC可以解决幻读的问题；对于当前读，MVCC则不能解决幻读的问题  

### 事务流程  

完整描述一下事务流程  

准备阶段  

1. 分配事务ID  

2. 如果隔离级别是REPEATABLE READ，创建read view  

3. 分配undo日志，把修改之前的数据写入undo日志  

4. 为undo日志的修改创建redo日志，写入redo log buffer  

5. 在buffer pool中修改数据页，回滚指针指向undo日志  

6. 为数据页的修改创建redo日志，写入redo log buffer  

提交阶段  

1.  写binlog到磁盘  
2. 修改undo日志状态为”purge“状态  
3. 根据innodb_flush_log_at_trx_commit判断是否需要立即把redo log buffer写入磁盘  
4. buffer pool中的数据页根据规则等待合适的时机写入到磁盘

恢复或者回滚阶段  

1. 根据redo日志中LSN和事务ID，数据文件中的LSN和binlog中的事务ID决定需要做恢复还是回滚  

2. 如果事务已提交，但数据页还未写入到磁盘，需要恢复，根据redo日志中的字段对数据页进行恢复  

3. 如果需要回滚，根据undo日志中的上一个版本数据进行回滚  

## 分布式事务  

分布式事务指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式节点之上。简单的说，就是一次大的事务由不同的小的事务组成，这些小的事务分布在不同的服务器上，且属于不同的应用，分布式事务需要保证这些小的事务，要么全部成功，要么全部失败。本质上说，分布式事务是为了保证不同数据库的数据一致性。一句话概括就是，一次业务操作需要跨多个数据源或者需要跨多个系统进行远程调用，就会产生分布式事务问题  

### 分布式事务的场景  

+ 单体系统访问多个数据库：一个服务需要调用多个数据库实例完成数据的增删改操作  

![one for all](https://gitee.com/liujinxi931204/typoraImage/raw/master/img/one%20for%20all.png)  

+ 多个微服务访问同一个数据库：多个服务需要调用一个数据库实例完成数据的增删改操作  

![all for one](https://gitee.com/liujinxi931204/typoraImage/raw/master/img/all%20for%20one.png)  

+ 多个微服务访问多个数据库：多个服务徐涛调用多个数据库实例完成数据的增删改操作  

![all for all](https://gitee.com/liujinxi931204/typoraImage/raw/master/img/all%20for%20all.png)  

### 分布式理论  

#### CAP定理   

CAP定理，又被叫做布鲁尔定理。对于设计分布式系统来说，CAP就是入门理论  

+ C(Consistency)：一致性。对于某个客户端来说，读操作能返回最新的写操作的结果。对于数据分布在不同节点上的数据来说，如果某个节点更新了数据，那么在其他节点如果都能读取到这个最新的数据，那么就称为强一致；如果有某个节点没有读取到，那么就是分布式不一致。  
+ A(Availability)：可用性。非故障节点在合理的时间内返回合理的响应(不是错误和超时的响应)。可用性的两个关键一个是合理的时间，一个是合理的响应。合理的时间指的是请求不能被无限阻塞，应该在合理的时间内给出返回；合理的响应是指系统应该能够明确返回结果并且结果是正确的。    
+ P((Partition tolerance)：分区容错性。当出现网络分区后，系统能够继续工作。即分布式系统在遇到某个节点或者网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务。  

熟悉CAP理论的人都知道，三者不能共有。  

对于CP来说，放弃可用性，追求一致性和分区容错性，zookeeper其实就是追求的强一致性  

对于AP来说，放弃强一致性，追求分区容错性和可用性，这是很多分布式系统设计时的选择，后面的BASE理论也是根据AP来扩展  

CAP理论中是忽略网络延迟的，但是在现实中这个是明显不可能的，所以总会有一定的时间是不一致的。同时CAP中选择两个，比如选择了CP，并不是说放弃了A。因为P出现的概率实在是太小了，大部分时间仍然需要保证CA。  

### BASE理论  

BASE理论是Basic Available(基本可用)、Soft state(软状态)、Eventually consistent(最终一致性)三个短语的缩写。是对CAP中AP的一个扩展  

1. 基本可用：分布式系统出现故障时，允许损失部分可用功能，保证核心功能可用  

2. 软状态：允许系统出现中间状态，这个状态不影响系统可用性，这里指的是CAP中的不一致  

3. 最终一致：最终一致是指经过一段时间后，所有节点数据都将会达到一致  

BASE解决了CAP理论中没有网络延迟，在BASE中用软状态和最终一致，保证了延迟后的一致性。BASE和ACID是相反的，它完全不同于ACID的强一致性模型，而是通过牺牲强一致性来获得可用性，并允许数据在一段时间内是不一致的，但最终达到一致状态。  

### 分布式事务协议  

#### 两阶段提交协议（2pc）  

分布式系统的一个难点是如何保证架构下多个节点在进行事务性操作的时候保持一致性。为实现这个目的，二阶段提交算法的成立基于以下假设  

+ 该分布式系统中，存在一个节点作为协调者（Coordinator），其他节点作为参与者（Cohorts），且节点字行间可以进行网络通信  

+ 所有节点都采用预式日志，且日志被写入后即被保存在可靠的存储设备上，即使节点损坏不会导致日志数据的消失  

+ 所有节点不会永久性损坏，即使损坏后仍然可以恢复  

##### 第一阶段（投票阶段）：  

+ 协调者节点向所有参与者节点询问是否可以执行提交操作(vote)，并开始等待各个参与者节点的响应  
+ 参与者节点执行询问发起为止的所有事务操作，并将undo信息、redo信息写入日志（注意：若成功这里其实每个参与者已经执行了事务操作，但是没有提交） 
+ 各个参与者节点响应协调者节点发起的询问，如果参与者节点的事务操作成功实际成功，则它返回一个"同意"消息；如果参与者节点的事务操作实际执行失败，则它会返回一个"中止"消息  
##### 第二阶段（提交执行阶段）：  

当协调者节点从所有参与者节点获得的相映消息都为"同意"时：  

+ 协调者节点向所有参与者节点发出"正式提交(commit)"的请求  

+ 参与者节点正式完成操作，并释放在整个事务期间内锁定的资源  

+ 参与者节点向协调者节点发送"完成"消息  

+ 协调者节点收到所有参与者节点反馈的"完成"消息后，完成事务  

##### 中断事务 ：  

如果任一参与者在第一阶段返回的响应消息为"中止"，或者协调者节点在第一阶段的询问超时之前无法获得所有参与者节点的响应消息时：  

+ 协调者节点向所有参与者节点发出"回滚操作(rollback)"的请求  

+ 参与者节点利用之前写入的undo日志执行回滚，并释放整个事务期间锁定的资源  

+ 参与者节点向协调者节点发送"回滚完成"消息  

+ 协调者节点收到所有参与者节点反馈的"回滚完成"消息后，取消事务  

**特别注意：不滚最后结果如何，第二阶段都会结束当前事务**  

![2pc](https://gitee.com/liujinxi931204/typoraImage/raw/master/img/2pc.png)  

##### 两阶段提交的缺点  

+ 单点问题：协调者在整个两阶段提交过程中扮演着举足轻重的作用，一旦协调者所在服务宕机，就会影响整个数据库集群的正常运行  

+ 同步阻塞：两阶段提交的过程中，所有的参与者都需要听从协调者的统一调度，期间处于阻塞状态而不能从事其他操作  

+ 阻塞资源：执行过程中，所有者参与者都是事务阻塞型的。当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态  

+ 数据不一致问题：协调者再发出commit消息之后宕机，而唯一接收到这条消息的参与者同时也宕机。那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，这就有可能造成数据不一致  

##### 两阶段提交的容错方式  

两阶段提交的异常情况主要分为如下三种情况  

+ 协调者正常，参与者宕机  

+ 协调者宕机，参与者正常  

+ 协调者、参与者都宕机  

对于第一种情况，若参与者在投票阶段之前宕机，则协调者不会收到"同意"的回复消息，协调者不会发送commit的命令，事务不会真正的提交；若参与者在提交阶段宕机，当它恢复后可以通过向其他参与者或者协调者询问事务是否应该提交，并作出相应的操作  

对于第二种情况，可以通过重新选举协调者来解决  

对于第三种情况，是两阶段提交无法解决的。协调者再发出commit消息之后宕机，而唯一接收到这条消息的参与者同时也宕机。那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，这就有可能造成数据不一致  

#### 三阶段提交协议（3pc）  

与两阶段提交不同的是，三阶段提交有两个改动点：  

+ 引入超时机智，同时在协调者和参与者中都引入超时机制  

+ 在第一阶段和第二阶段之前引入了一个CanCommit阶段，PreCommit阶段保证最后提交之前参与者的状态都是一致的    

这样三阶段提交就有CanCommit、PreCommit、DoCommit三个阶段。  

##### CanCommit阶段  

3PC的CanCommit阶段其实是资源的确认。协调者向参与者发送CanCommit请求，参与者如果可以提交返回Yes响应，否则返回No响应：  

+ 事务询问：协调者向参与者发送CanCommit请求。询问是否可以执行事务提交操作。然后开始等待参与者的响应  
+ 响应反馈：参与者接到CanCommit请求之后，正常情况下，如果其自身认为可以顺利执行事务，则返回Yes响应，并进入预提交状态，否则返回No响应  

##### PreCommit阶段    

协调者根据参与者的反应情况来决定是否可以执行事务的PreCommit操作。根据响应，有以下两种情况  

+ 假如协调者从所有的参与者获得反馈都是Yes响应，那么就会执行事务的预提交  
  + 发送预提交请求：协调者向参与者发送PreCommit请求后，并进入Prepared阶段  
  + 事务预提交：参与者接收到PreCommit请求后，会执行事务操作，并将undo和redo信息写入日志中  
  + 响应反馈：如果参与者成功的执行了事务操作，则返回ACK响应，同时开始等待最终指令  
+ 假如有任何一个参与者向协调者发送了No响应，或者等待超时之后，协调者没有接收到参与者的响应，那么就执行事务的中断  
  + 发送中断请求：协调者向所有参与者发送Abort请求  
  + 中断事务：参与者收到来自协调者的Abort请求之后（或者超时之后，任未收到协调者的请求），执行事务的中断   

##### DoCommit阶段    

该阶段执行真正的提交，也可以分为以下两种情况：  

+ 执行提交：  

  + 发送提交请求：协调者收到参与者发送的ACK响应，那么它将从预提交状态进入到提交状态，并向所有的参与者发送DoCommit请求  

  + 事务提交：参与者收到DoCommit请求之后，执行正式提交，并在它完成事务提交之后释放所有事务资源  

  + 响应反馈：事务提交完成后，向协调者发送ACK响应  

  + 完成事务：协调者接收到所有参与者的ACK响应之后，完成事务  
+ 中断事务：  
  + 发送中断请求：协调者向所有参与者发送Abort请求  
  + 事务回滚：参与者接收到Abort请求之后，利用其在阶段二记录的undo日志执行事务的回滚，并在完成回滚之后释放所有的事务资源  
  + 反馈结果：参与者事务回滚之后，向协调者发送ACK请求  
  + 中断事务：协调者接收到参与者反馈的ACK消息之后，执行事务的中断  
  +   

这里协调者如果没有接收到参与者发送的ACK响应（可能是接收这发送的不是ACK响应或者响应超时），那么就会执行中断事务  

![3pc](https://gitee.com/liujinxi931204/typoraImage/raw/master/img/3pc.png)   

相对于2PC，3PC主要解决的单点故障问题并减少阻塞，因为一旦参与者无法及时收到来自协调者的信息后，会默认执行commit操作，而不会一直持有事务的资源并处于阻塞状态  





