redis提高了复制功能，实现了相同数据的多个redis副本，复制功能时redis高可用的基础  
### 配置  
#### 建立复制  
参与复制的redis实例划分为主节点(master)和从节点(slave)。默认情况下，redis都是主节点。每个从节点只能有一个主节点，而主节点可以同时具有多个从节点。复制的数据流是单向的，只能由主节点复制到从节点。配置复制的方式有以下三种  
+ 在配置文件中加入slave {masterHost} {masterPort}随redis启动生效  
+ 在redis-server的启动命令后面加入--slaveof {masterHost} {masterPort}生效  
+ 直接使用命令slaveof {masterHost} {masterPort}生效  
#### 断开复制  
slaveof命令不但可以建立复制，还可以在从节点上执行slaveof no one来断开与主节点复制关系  
断开复制主要流程  
+ 断开与主节点复制关系  
+ 从节点晋升为主节点  
从阶段断开复制后并不会抛弃原有数据，只是无法再获取主节点上的数据变化  
通过slaveof命令还可以实现切主操作，所谓切主操作是指把当前从节点对主节点的复制切换到另一个主节点。执行slaveof {newMasterHost} {newMasterPort}命令即可  
切主操作流程如下：
+ 断开与旧主节点复制关系  
+ 与新主节点建立复制关系  
+ 删除从节点当前所有数据  
+ 对新主节点进行复制操作  
切主后从节点会清空之前所有的数据  
默认情况下，从节点使用slave-read-only=yes配置为只读模式。由于复制只能从主节点到从节点，对于从节点的任何修改住节点都无法感知，修改从节点数据会造成主从数据不一致  
redis提供了repl-disable-tcp-nodelay参数用于控制是否关闭TCP_NODELAY，默认关闭  
+ 当关闭时，主节点产生的命令数据无论大小都会及时地发送给从节点，这样主从之间延迟会变小，但增加了网络带宽消耗  
+ 当开启时，主节点会合并比较小的TCP数据包从而节省带宽。这种配置节省了带宽但增大了主从之间的延迟  
### 拓扑  
#### 一主一从  
一主一从是最简单的复制拓扑结构，用于主节点出现宕机时从节点提供故障转移支持。当应用写命令并发量较高且需要持久化时，可以只在从节点上开启AOF，这样既保证数据安全性同时也避免了持久化对主节点的性能干扰。但需要注意，当主节点关闭持久化功能时，如果主节点脱机要避免主节点自动重启操作。因为主节点之前没有开启持久化功能重启之后数据集为空，这时如果从节点继续复制会导致从节点的数据也被清空，丧失了持久化的意义。安全的做法是在从节点上执行slaveof no one断开与主节点的复制关系  
#### 一主多从  
一主多从(又称为星形拓扑结构)使得应用端可以利用多个从节点实现读写分离。对于读占比较大的场景，可以把读命令发送到从节点来分担主节点压力。对于写并发量较高的场景，多个从节点会导致主节点写命令的多次发送而过度消耗网络带宽，同时也增加了主节点的负载影响服务稳定性  
#### 树状主从  
树状主从结构(又称为树状拓扑结构)使得从节点不但可以复制主节点数据，同时可以作为其他从节点的主节点继续向下层复制。通过引入复制中间层，可以有效降低主节点负载和需要传送给从节点的数量  
### 原理  
#### 复制过程  
![title](https://gitee.com/liujinxi931204/image/raw/master/gitnote/2020/09/22/1600765240920-1600765240922.png)  
复制过程大致分为6个过程  
1. 保存主节点(masyter)信息  
执行slaveof后从节点只保存主节点的地址信息便直接返回，这时建立复制流程还没有开始  
2. 从节点(slave)内部通过个每秒运行的定时任务维护复制相关逻辑，当定时任务发现存在新的主节点后，会尝试与该节点建立网络连接  
从节点会建立一个socket套接字，专门用于接受主节点发送的复制命令  
如果从节点无法建立连接，定时任务会无限重试直到连接成功或者执行slaveof no one取消复制  
3. 发送ping命令  
连接建立成功后从节点发送ping请求首次通信，ping请求的主要目的是检测主从之间的网络套接字是否可用以及主节点当前是否可以接受处理命令  
如果发送ping命令之后，从节点没有收到主节点的pong的回复或者超时，从节点会断开连接，下次定时任务会发起重连  
4. 权限验证  
如果主节点设置了requirepass参数，则需要密码验证，从节点必须配置masterauth参数保证与主节点相同的密码才能通过验证；如果验证失败复制将终止，从节点重新发起复制流程  
5. 同步数据集  
主从复制连接正常通信后，对于首次建立复制的场景，主节点会把持有的数据全部发送给从节点，这部分操作是耗时最长的步骤。新版同步划分为全量同步和部分同步  
6. 命令持续复制  
当主节点把当前的数据都同步给从节点后，便完成了复制的建立流程。接下来主节点会持续地把写命令发送给从节点，保证主从数据一致性  
#### 数据同步  
同步过程分为：全量复制和部分复制  
+ 全量复制  
一般用于初次复制场景，redis早期支持的复制功能只有全量复制，它会把主节点的数据一次性发送给从节点，当数据量较大时，会对主从节点和网络造成很大的开销  
流程说明  
1. 从节点判断无法进行部分复制，向主节点发送全量复制的请求；或从节点发送部分复制的请求，但主节点判断无法进行部分复制  
2. 主节点收到全量复制的命令后，执行bgsave，在后台生成RDB文件，并使用一个缓冲区(复制缓冲区)记录从现在开始执行的所有写命令  
3. 主节点的bgsave执行完成后，将RDB文件发送给给从节点；从节点首先清除自己的旧数据，然后载入接受的RDB文件，将数据库状态更新至主节点执行bgsave是的数据库状态  
+ 对于数据量较大的主节点，比如生成的RDB文件超过6GB以上时要格外小心。传输文件会非常耗时，如果传输时间超过了repl-timeout所配置的值(默认60秒)，从节点将放弃接受RDB文件并清理已经下载的临时文件，导致全量复制失败  
4. 主节点将前述的复制缓冲区中的所有写命令发送给从节点，从节点执行这些写命令，将数据库状态更新至主节点的最新状态  
5. 如果从节点开启了AOF，则会触发bgrewriteao的执行，从而保证AOF文件更新至主节点的最新状态  
+ 部分复制  
用于处理在主从复制中因网络闪断等原因造成的数据丢失场景，当从节点再次连上主节点后，如果条件允许，主节点会补发丢失数据给从节点。因为补发的数据远远小于全量数据，可以有效避免全量复制的过高开销  
psync命令运行需要以下组件支持  
+ 主从节点各自复制偏移量  
+ 主节点复制积压缓冲区  
+ 主节点运行id  
1. 复制偏移量  
参与复制的主从节点都会维护自身复制偏移量。主节点(master)在处理完写入命令后，会把命令的字节长度做记录，统计信息在info replication中master_repl_offset指标中  
从节点(slave)每秒钟上报自身的复制偏移量给主节点，因此主节点也会保存从节点的复制偏移量  
从节点在接收到主节点发送到的命令后，也会累加记录自身的偏移量，统计信息记录在info replication中的slave_repl_offset  
可以通过主节点的统计信息，计算出master_repl_offset-slave_offset字节量，判断主从节点复制相差的数据量，根据这个差值可以判定当前复制的健康度。如果主从节点之间复制偏移量相差较大，则可能是网络延迟或命令阻塞等原因引起  
![title](https://gitee.com/liujinxi931204/image/raw/master/gitnote/2020/09/23/1600847272979-1600847273024.png)  
2. 复制积压缓冲区  
复制积压缓冲区是保存在主节点上的一个固定长度的队列，默认大小为1MB，当主节点有连接的从节点(slave)时被创建，这时主节点(master)响应写命令时，不但会把命令发送给从节点，还会写入复制积压缓冲区  
由于缓冲区本质上是先进先出的定长队列，所以能实现保存最近已复制数据的功能，用于部分复制和复制命令丢失的数据补救。复制缓冲区相关信息保存在info replication中  
3. 主节点运行ID  
每个redis节点启动后都会动态分配一个40位的十六进制字符串作为运行ID。运行ID的主要作用是用来唯一区别reids节点。如果只使用ip+port方式识别主节点，那么主节点重启变更了整体数据集，从节点再基于偏移量复制数据将是不安全的，因此当运行ID变化后从节点将做全量复制  
需要注意的是redis关闭后再启动，运行ID会随之改变  
可以使用debug reload命令重新加载RDB并保持运行ID不变，从而有效避免不必要的全量复制  
debug reload命令会阻塞当前redis节点主线程，阻塞期间会生成本地RDB快照并清空数据之后再加载RDB文件。因此对于大数据量的主节点和无法容忍阻塞的应用场景，谨慎使用  
4. psync命令  
从节点使用psync命令完成部分复制和全量复制，命令格式: `psync {runId} {offset}`，参数含义如下：  
runId：从节点所复制主节点的运行Id  
offset：当前从节点已复制的数据偏移量  
![title](https://gitee.com/liujinxi931204/image/raw/master/gitnote/2020/09/23/1600851957217-1600851957218.png)  
1. 首先，从节点根据当前状态，决定如何调用psync命令  
+ 如果从节点之前从未执行过slaveof或者最近执行了slaveof no one，则从节点发送命令为`psync ? -1`,向主节点请求全量复制 
+ 如果之前执行了slave of，则发送命令`psync <runid> <offset>`，其中runid为上次复制的主节点的runid，offset为上次复制截止时从节点保存的复制的偏移量  
6. 主节点根据收到的psync命令，及当前服务器状态，决定执行全量复制还是部分复制  
+ 如果主节点的版本低于redis2.8,则返回-ERR回复，此时从节点重新发送sync命令执行全量复制  
+ 如果主节点版本够新，且runid与从节点发送的runid相同，且从节点发送的offset之后的数据再复制积压缓冲区中都存在，则回复+CONTINUE，表示将进行部分复制，从节点等待主节点发送其缺少的数据即可  
+ 如果主节点版本够新，但是runid与从节点发送的runid不同，或者从节点发送的offset之后的数据已不在复制积压缓冲区(在队列中被挤出了),则回复+FULLRESYNC <runid> <offset>，表示要进行全量复制，其中runid表示当前主节点的runid，offset表示当前主节点的offset，从节点保存这两个值，以备使用  
#### 心跳命令  
主从节点在建立复制后，它们之间维护者长连接并彼此发送心跳命令  
![title](https://gitee.com/liujinxi931204/image/raw/master/gitnote/2020/09/24/1600932893195-1600932893233.png)  
主从心跳判断机制  
1. 主从节点彼此都有心跳检测机制，各自模拟成对方的客户端进行通信，通过client list命令查看复制相关客户端信息，主节点的连接状态为flags=M，从节点的连接状态为flags=S  
2. 主节点默认每间隔10秒对从节点发送ping命令，判断从节点的存活性和连接状态。可通过参数repl-ping-slave-period控制发送频率  
3. 从节点在主线程中每隔1秒发送replconf ack {offset}命令，给主节点上报自身当前的复制偏移量。replconf命令的主要
作用如下 ：  
+ 实时检测从节点网络状态  
+ 上报自身复制偏移量，检查复制数据是否丢失，如果从节点丢失数据，再从主节点的复制缓冲区中拉取丢失数据  
+ 实现保证从节点的数量和延迟性功能，通过min-slaves-to-write、min-salves-max-lag参数配置定义  
 主从复制根据replconf命令判断从节点超时时间，体现在info replication统计中的lag信息中，lag表示与从节点最后一次通信延迟的描述，正常延迟应该再0-1之间。如果超过repl-timeout配置的值(默认60秒)，则判断从节点下线并断开复制客户端连接。即使主节点判断从节点下线后，如果从节点重复恢复，心跳检测会继续进行  
#### 异步复制  
主节点不但负责数据读写，还负责把写命令同步给从节点。写命令的发送过程是异步完成，也就是说主节点自身处理完写命令后直接返回给客户端，并不等待从节点复制完成  
![title](https://gitee.com/liujinxi931204/image/raw/master/gitnote/2020/09/24/1600935416776-1600935416778.png)  
### 读写分离  
对于读占比较高的场景，可以通过把一部分读流量分摊到从节点(slave)来减轻主节点(master)压力，需要注意永远只对主节点执行写操作  
![title](https://gitee.com/liujinxi931204/image/raw/master/gitnote/2020/09/24/1600936908111-1600936908112.png)  
当使用从节点响应读请求时，业务端可能会遇到如下问题：  
+ 复制数据延迟  
+ 读到过期数据  
+ 从节点故障  
1. 数据延迟  
redis复制数据的延迟是由于异步复制特性是无法避免的，取决于网络带宽和命令阻塞情况  
2. 读到过期数据  
当主节点存储大量设置超时的数据时，如缓存数据，redis内部需要维护过期数据删除策略，删除策略主要有两种：惰性删除和定时删除  
+ 惰性删除:主节点每次处理读取命令时，都会检查键是否超时，如果超时则执行del操作删除键对象，之后del命令也会异步发送给从节点。需要注意的是为了保证复制的一致性，从节点自身永远不会主动删除超时数据  
+ 定时删除：redis主节点在内部定时任务会循环采样一定数量的键，当发现采样的键过期时执行del命令，之后再同步给从节点  
3. 从节点故障  
对于从节点的故障问题，需要在客户端维护可用从节点列表，当从节点故障时立刻切换到其他从节点或主节点上  
### 主从配置不一致  
主从配置不一致是一个很容易忽视的问题。对于有些配置主从之间是可以不一致的，但是对于内存相关的配置必须要一致  
### 规避全量复制  
1. 第一次建立复制  
由于第一次建立复制，从节点不包括任何主节点数据，因此必须进行全量复制才能完成数据同步。对于这种情况全量入职无法避免。当对数据量比较大请流量较高的主节点添加从节点时，建议在低峰时进行操作或者尽量规避使用大数据量的redis节点  
2. 节点运行ID不匹配  
当主从复制关系建立后i，从节点会保存主节点的运行ID，如果此时主节点因故障重启，那么它的运行ID会改变，从节点发现主节点运行ID不匹配时，会认为自己复制的是一个新的主节点从而进行全量复制  
3. 复制积压缓冲区不足  
当主从网络中断后，从节点再次连接上主节点时会发送psync {runID} {offset}命令请求部分复制，如果请求的偏移量不在主节点的积压缓冲区内，则无法提供给从节点数据，因此部分复制会退化为全量复制。积压缓冲区默认大小为1MB，对于大流量的场景这显然不够  
### 复制风暴  
复制风暴是指大量从节点对同一主节点或者对同一台机器的多个主节点短时间内发起的全量复制的过程。复制风暴对发起复制的主节点或者机器造成大量开销，导致CPU、内存、带宽消耗  
1. 单主节点复制风暴  
单主节点复制风暴一般发生在主节点挂载多个从节点的场景。解决方案首先可以减少主节点挂载从节点的数量或者采用树状复制结构，加入中间层从节点用来保护主节点  
2. 单机器复制风暴  
由于redis的单线程架构，通常单台机器会部署多个redis实例。当一台机器上同时部署多个主节点，如果这台机器出现故障或网络长时间中断，当它重启恢复后，会有大量从节点针对这台机器的主节点进行全量复制，会造成当前机器网络带宽耗尽  
+ 应该把主节点尽量分散在多台机器上，避免在单台机器上部署过多的主节点  
+ 当主节点所在机器故障后提供故障转移机制，避免机器恢复后进行密集的全量复制  



























  

